{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추천을 위한 알고리즘을 분류해보면 크게 메모리 기반과 모델 기반으로 나눌 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리 기반 추천 : 추천을 위한 데이터를 모두 메모리에 가지고 있으면서 추천이 필요할 때마다 이 데이터를 사용해서 계산을 해서 추천하는 방식  \n",
    "모델 기반 추천 : 데이터로부터 추천을 위한 모델을 구성한 후 이 모델만 저장하고, 실제 추천을 할 때에는 이 모델을 사용해서 추천을 하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리 기반 추천은 원래 데이터를 충실하게 사용하는 장점이 있지만 대량의 데이터를 다뤄야 하는 상용 사이트에서 계신시간이 너무 오래걸린다는 단점이 있다.\n",
    "<br/>\n",
    "모델 기반 추천 방식은 데이터는 모형을 만드는 데만 사용하고 모델이 만들어지면 원래 데이터는 사용하지 않기 때문에 대규모 사용 사이트에서 필요한 빠른 반응이 가능하지만 모델을 만드는 과정에서 많은 계산이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 메모리 기반 추천은 개별 사용자의 데이터에 집중하고, 모델 기반 추천은 전체 사용자의 평가 패턴으로부터 모델을 구성하기 때문에 데이터가 가지고 있는 약한 신호도 더 잘 잡아내는 장점이 있다.\n",
    "<br/>\n",
    "이번 장에서는 대표적인 모델 기반 추천 알고리즘인 MF 방식 추천에 대해 알아보기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Matrix Factorization 방식의 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(사용자 X 아이템) 으로 구성된 하나의 행렬을 2개의 행렬로 분해하는 방법이다.  \n",
    "앞서 CF 를 구현할 때 사용한 full matrix 는 (사용자 X 아이템) 형태의 2차원 행렬이다.  \n",
    "이를 사용자 잠재요인행렬과 아이템 잠재요인행렬로 나눌 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://velog.velcdn.com/images/sangyun/post/07d390cb-b5b2-4ece-a095-b60a2805af8a/image.png' width = 600 height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R 행렬을 사용자행렬P와 아이템행렬Q로 쪼개어 분석하는 것이 MF 방식이다.  \n",
    "P, Q 행렬에서 공통인 K개의 요인을 잠재요인으로 부르는데 사용자와 아이템의 특성을 K개의 잠재요인을 사용해서 분석하는 것이 MF 방식의 원리이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 SGD를 사용한 MF 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MF의 핵심은 주어진 사용자, 아이템의 관계를 가장 잘 설명하는 P, Q 행렬을 분해하는 것이다.  \n",
    "주어진 (사용자X아이템) 평점 행렬인 R로부터 P,Q를 분해하는 알고리즘을 개념적으로 설명하면 다음과 같다.\n",
    "1. 잠재요인의 개수 K를 정한다. K는 경험에 의한 직관적으로 정해도 되고, 다양한 K를 비교하면서 최적의 수를 정해도 된다.\n",
    "2. 주어진 K에 따라 P, Q 행렬을 만들고 초기화한다.\n",
    "3. 주어진 P,Q 행렬을 사용해 예측 평점을 구한다.\n",
    "4. 실제 평점과 예측 평점을 비교해서 오차를 구하고, 이 오차를 줄이기 위해 P,Q 를 수정한다.\n",
    "5. 전체 오차가 미리 정해진 기준값 이하가 되거나 미리 정해진 반복 횟수에 도달할 떄까지 3으로 돌아가서 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 핵심은 4에서 예측 오차를 줄이기 위해 어떻게 수정하는가이다.  \n",
    "가장 일반적인 방법은 기계학습에서 많이 사용되는 SGD 방법을 적용하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD 방법을 적용하는 자세한 내용은 아래 링크 참조하자.  \n",
    "https://bladejun.tistory.com/57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 SGD를 사용한 MF 기본 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./data/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.8837 \n",
      "Iteration: 20 ; Train RMSE = 0.7089 \n",
      "Iteration: 30 ; Train RMSE = 0.5924 \n",
      "Iteration: 40 ; Train RMSE = 0.5403 \n",
      "Iteration: 50 ; Train RMSE = 0.5130 \n",
      "Iteration: 60 ; Train RMSE = 0.4962 \n",
      "Iteration: 70 ; Train RMSE = 0.4852 \n",
      "Iteration: 80 ; Train RMSE = 0.4773 \n",
      "Iteration: 90 ; Train RMSE = 0.4715 \n",
      "Iteration: 100 ; Train RMSE = 0.4669 \n"
     ]
    }
   ],
   "source": [
    "# MF class\n",
    "class MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    def train(self): \n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # SGD for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1, rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f \" % (i+1, rmse))\n",
    "        return training_process\n",
    "\n",
    "    # Rating prediction for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # SGD to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "\n",
    "# 전체 데이터 사용 MF\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = MF(R_temp, K=30, alpha=0.01, beta=0.02, iterations=100, verbose=True)\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과가 좋게 나오는데 train/test set 을 나누지 않으므로 당연한 결과라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 train test 분리 MF 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3장의 CF 와 마찬가지로 train/test set 분리하여 훈련한다.  \n",
    "차이점은 3장의 CF는 sklearn의 train_test_split 을 사용했는데 여기서는 sklearn 의 shuffle을 사용한다.  \n",
    "3장에서는 층화추출을 할 수 있지만 여기서는 무작위로 섞기 때문에 극단적인 경우 특정 사용자의 모든 데이터가 train이나 test set 한 곳에 들어갈 수 있다.  \n",
    "어떤 것을 사용할 지는 데이터분석의 목적에 따라서 선택하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "from sklearn.utils import shuffle\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=42)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New MF class for training & testing\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose = True):\n",
    "        self.R = np.array(ratings)\n",
    "        # user_id, item_id를 R의 index 와 매핑하기 위한 dictionary 생성\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_id_item = dict(index_item_id)\n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set 의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x,y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "        \n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    # SGD to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    \n",
    "    # Test set 을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)): # test 데이터에 있는 각 데이터에 대해서\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x,y,z])\n",
    "            self.R[x,y] = 0 # setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error / len(self.test_set))\n",
    "    \n",
    "    # Training 하면서 test set 의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9678 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9426 ; Test RMSE = 0.9588\n",
      "Iteration: 30 ; Train RMSE = 0.9311 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9242 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9192 ; Test RMSE = 0.9452\n",
      "Iteration: 60 ; Train RMSE = 0.9152 ; Test RMSE = 0.9438\n",
      "Iteration: 70 ; Train RMSE = 0.9114 ; Test RMSE = 0.9427\n",
      "Iteration: 80 ; Train RMSE = 0.9072 ; Test RMSE = 0.9417\n",
      "Iteration: 90 ; Train RMSE = 0.9022 ; Test RMSE = 0.9405\n",
      "Iteration: 100 ; Train RMSE = 0.8957 ; Test RMSE = 0.9389\n"
     ]
    }
   ],
   "source": [
    "# Testing MF RMSE\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.83665804 3.33239295 3.21311212 ... 3.40627265 3.48089157 3.51967726]\n",
      " [4.02409366 3.51583752 3.31831102 ... 3.50442026 3.6210149  3.61919936]\n",
      " [3.25771844 2.71172472 2.51663725 ... 2.72739058 2.83967058 2.8385036 ]\n",
      " ...\n",
      " [4.2647238  3.70848446 3.50990559 ... 3.70895564 3.84126338 3.82485628]\n",
      " [4.41500302 3.88447175 3.68602581 ... 3.90041141 4.01516739 4.01293757]\n",
      " [3.73420802 3.29681902 3.07985555 ... 3.25602468 3.36415046 3.36816193]]\n",
      "\n",
      "3.3323929457051373\n"
     ]
    }
   ],
   "source": [
    "# Printing predictions\n",
    "print(mf.full_prediction())\n",
    "print()\n",
    "print(mf.get_one_prediction(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습문제\n",
    "1. shuffle() 대신 train_test_split 을 사용하여 분리하도록 수정하고 실행해보자.\n",
    "2. 실행결과에서 RMSE가 많이 차이난다면 왜 차이가 발생했을 지 설명해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./data/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>877</td>\n",
       "      <td>381</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>815</td>\n",
       "      <td>602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>94</td>\n",
       "      <td>431</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>416</td>\n",
       "      <td>875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>500</td>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21271</th>\n",
       "      <td>399</td>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34014</th>\n",
       "      <td>222</td>\n",
       "      <td>580</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81355</th>\n",
       "      <td>551</td>\n",
       "      <td>162</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65720</th>\n",
       "      <td>803</td>\n",
       "      <td>988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11627</th>\n",
       "      <td>72</td>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "75721      877       381       4\n",
       "80184      815       602       3\n",
       "19864       94       431       4\n",
       "76699      416       875       2\n",
       "92991      500       182       2\n",
       "...        ...       ...     ...\n",
       "21271      399       684       3\n",
       "34014      222       580       3\n",
       "81355      551       162       5\n",
       "65720      803       988       1\n",
       "11627       72       177       4\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ratings_train, ratings_test = train_test_split(ratings, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9678 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9426 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9311 ; Test RMSE = 0.9511\n",
      "Iteration: 40 ; Train RMSE = 0.9242 ; Test RMSE = 0.9472\n",
      "Iteration: 50 ; Train RMSE = 0.9192 ; Test RMSE = 0.9450\n",
      "Iteration: 60 ; Train RMSE = 0.9151 ; Test RMSE = 0.9434\n",
      "Iteration: 70 ; Train RMSE = 0.9111 ; Test RMSE = 0.9422\n",
      "Iteration: 80 ; Train RMSE = 0.9066 ; Test RMSE = 0.9410\n",
      "Iteration: 90 ; Train RMSE = 0.9011 ; Test RMSE = 0.9394\n",
      "Iteration: 100 ; Train RMSE = 0.8939 ; Test RMSE = 0.9374\n"
     ]
    }
   ],
   "source": [
    "# Testing MF RMSE\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 MF의 최적 파라미터 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K, iteratinos, $\\alpha$, $\\beta$ 와 같은 파라미터가 정확도에 영향을 미친다.  \n",
    "잠재요인의 수인 K의 경우 커질수록 다양한 패턴을 학습할 수 있으므로 정확도가 높아지는데, 지나치게 커지면 과적합이 발생한다.  \n",
    "따라서 K가 커짐에 따라 test set 의 정확도가 커지다가 감소하는 모습을 예상할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterations 도 마찬가지 현상이 발생한다. 즉 최적의 파라미터를 찾는게 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서는 다음과 같은 절차로 최적값을 찾아보도록 한다.\n",
    "1. 최적의 K가 대략 어떤 수인지 확인하기 위해 50~260까지 간격 10으로 정확도를 계산한다.\n",
    "2. 최적의 RMSE를 보이는 K를 확인한 후 이 숫자 전후 10의 K에 대해 1의 간격으로 다시 한번 RMSE를 계산하여 K를 찾는다.\n",
    "3. iterations 는 학습 과정에서 충분히 큰 숫자를 주어서 RMSE가 어떻게 변화하는지 관찰해서 주어진 K에 대해 최적의 iteration 값을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50\n",
      "Iteration: 10 ; Train RMSE = 0.9680 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9431 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9318 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9252 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9206 ; Test RMSE = 0.9452\n",
      "K = 60\n",
      "Iteration: 10 ; Train RMSE = 0.9681 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9432 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9320 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9254 ; Test RMSE = 0.9473\n",
      "Iteration: 50 ; Train RMSE = 0.9210 ; Test RMSE = 0.9451\n",
      "K = 70\n",
      "Iteration: 10 ; Train RMSE = 0.9681 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9433 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9322 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9256 ; Test RMSE = 0.9473\n",
      "Iteration: 50 ; Train RMSE = 0.9212 ; Test RMSE = 0.9452\n",
      "K = 80\n",
      "Iteration: 10 ; Train RMSE = 0.9682 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9434 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9323 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9258 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9215 ; Test RMSE = 0.9452\n",
      "K = 90\n",
      "Iteration: 10 ; Train RMSE = 0.9682 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9434 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9323 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9259 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9216 ; Test RMSE = 0.9452\n",
      "K = 100\n",
      "Iteration: 10 ; Train RMSE = 0.9682 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9435 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9324 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9260 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9217 ; Test RMSE = 0.9452\n",
      "K = 110\n",
      "Iteration: 10 ; Train RMSE = 0.9682 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9435 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9325 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9261 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9218 ; Test RMSE = 0.9452\n",
      "K = 120\n",
      "Iteration: 10 ; Train RMSE = 0.9682 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9435 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9325 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9261 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9219 ; Test RMSE = 0.9452\n",
      "K = 130\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9325 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9262 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9220 ; Test RMSE = 0.9452\n",
      "K = 140\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9326 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9262 ; Test RMSE = 0.9473\n",
      "Iteration: 50 ; Train RMSE = 0.9220 ; Test RMSE = 0.9452\n",
      "K = 150\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9326 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9263 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9221 ; Test RMSE = 0.9452\n",
      "K = 160\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9326 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9263 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9222 ; Test RMSE = 0.9452\n",
      "K = 170\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9326 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9263 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9222 ; Test RMSE = 0.9452\n",
      "K = 180\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9263 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9222 ; Test RMSE = 0.9452\n",
      "K = 190\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9264 ; Test RMSE = 0.9473\n",
      "Iteration: 50 ; Train RMSE = 0.9223 ; Test RMSE = 0.9452\n",
      "K = 200\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9264 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9223 ; Test RMSE = 0.9452\n",
      "K = 210\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9436 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9264 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9223 ; Test RMSE = 0.9452\n",
      "K = 220\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9437 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9264 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9223 ; Test RMSE = 0.9452\n",
      "K = 230\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9437 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9264 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9224 ; Test RMSE = 0.9452\n",
      "K = 240\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9780\n",
      "Iteration: 20 ; Train RMSE = 0.9437 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9264 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9224 ; Test RMSE = 0.9452\n",
      "K = 250\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9437 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9327 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9265 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9224 ; Test RMSE = 0.9452\n",
      "K = 260\n",
      "Iteration: 10 ; Train RMSE = 0.9683 ; Test RMSE = 0.9781\n",
      "Iteration: 20 ; Train RMSE = 0.9437 ; Test RMSE = 0.9587\n",
      "Iteration: 30 ; Train RMSE = 0.9328 ; Test RMSE = 0.9512\n",
      "Iteration: 40 ; Train RMSE = 0.9265 ; Test RMSE = 0.9474\n",
      "Iteration: 50 ; Train RMSE = 0.9224 ; Test RMSE = 0.9452\n"
     ]
    }
   ],
   "source": [
    "# 최적의 K값 찾기\n",
    "results = []\n",
    "index = []\n",
    "for K in range(50, 261, 10):\n",
    "    print('K =', K)\n",
    "    R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "    mf = NEW_MF(R_temp, K=K, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 iterations 값 찾기\n",
    "summary = []\n",
    "for i in range(len(results)):\n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j+1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(index, [x[2] for x in summary])\n",
    "plt.ylim(0.93, 0.95)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 방법으로 $\\alpha, \\beta$ 에서도 최적값을 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
